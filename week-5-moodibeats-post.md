The goal of our team’s project was to deliver royalty-free music audio data by mood. The DS-specific goal was to obtain new songs, initially, later new YouTube music videos, and classify them into one of 6 different moods for return on request to Web frontend. The team’s music data consideration evolved from Spotify, to Jemendo, to Soundcloud and Free Music Archive for the first 2 project weeks, and ultimately to the YouTube Data API v3. At the end of Week 2, DS had one Django app that was working with the team-curated songs from Soundcloud, and one Flask app built around Free Music Archive data. 

In week 3, DS team members were instructed to switch to one web API only and to work with data from the YouTube API. We selected Sammy Lee’s Django app for the API, given that he had created the Django app with a RESTful browsable framework. John Humphreys wrote the initial Python code to interact with the YouTube API for DS. SL adapted that code within the Django app to consume “videos.list” and “commentThreads.list” resources from the API.  

By week 4, SL had found a method to automate new video data ingest into the Django app, using Heroku’s Scheduler add-on (similar to running cron jobs). He was responsive to Web’s Django endpoint requirements, and he manually labeled 400+ videos with a mood for each. JH’s work during this time was to write and maintain an NLP-based machine learning classifier pipeline. The plan was to perform NLP on each video’s comments and use the resultant NLP data to create a multiclass RandomForest ML classifier for mood for new videos. This pipeline included multiple steps, from comments processing, to passing comments through TextBlob to get its unique sentiment analysis for each comment, to engineering additional data features from the TextBlob results, to fitting two different ML models to train and test splits of the data. SL also wrote a machine learning classifier pipeline, fitting HashingVectorizer and Logistic Regression to the video descriptions rather than video comments.

Conclusion: To classify music videos by mood requires either high-signal metadata, a myriad of videos, or both. Our challenges were that the comments and description data was of poor relevance to the videos and that we had relatively very few videos to work with. However, we did consume 3rd party API data, host and interact with it on a web application, use the pandas library to manipulate and transform it in Jupyter notebooks, apply NLP, feature engineer the resultant data, and access the scikit-learn library to fit three different classification models. 
