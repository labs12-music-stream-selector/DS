{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec and Doc2Vec to get numeric representations of YouTube video\n",
    "## comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.7.3)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.8.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.9.148)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.148 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.148)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.148->boto3->smart-open>=1.7.0->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.148->boto3->smart-open>=1.7.0->gensim) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim\n",
    "from gensim.models import doc2vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[FREE DL] Dave East Type Beat \"Momma Workin\" (...</td>\n",
       "      <td>kQKLl6jXipQ</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logic - Indica Badu ft. Wiz Khalifa [Instrumen...</td>\n",
       "      <td>-QQUaWtMW3w</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>【Off Vocal】Yasuha. - I Lost Your Love feat. Ha...</td>\n",
       "      <td>1QejWtVKE8s</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shiva In Exile - Earth Tone (Instrumental)</td>\n",
       "      <td>4zrLieLZ_i8</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8 Remix - Almighty ft. Varios [INSTRUMENTAL + ...</td>\n",
       "      <td>kmLvR68_nLg</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         video_title     video_id  \\\n",
       "0  [FREE DL] Dave East Type Beat \"Momma Workin\" (...  kQKLl6jXipQ   \n",
       "1  Logic - Indica Badu ft. Wiz Khalifa [Instrumen...  -QQUaWtMW3w   \n",
       "2  【Off Vocal】Yasuha. - I Lost Your Love feat. Ha...  1QejWtVKE8s   \n",
       "3         Shiva In Exile - Earth Tone (Instrumental)  4zrLieLZ_i8   \n",
       "4  8 Remix - Almighty ft. Varios [INSTRUMENTAL + ...  kmLvR68_nLg   \n",
       "\n",
       "             moods  \n",
       "0            CHILL  \n",
       "1            HAPPY  \n",
       "2            CHILL  \n",
       "3            CHILL  \n",
       "4  CONFIDENT-SASSY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df = pd.read_csv('new_videos.csv')  # note that this csv data does not have comments column\n",
    "videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2raUmsKIG6U</td>\n",
       "      <td>['That is some cool grafiti song, sick!', 'Dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3XAkH0w3QLc</td>\n",
       "      <td>['the \"jake young\" at the begining scared me l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hXe0Elz7WV8</td>\n",
       "      <td>['This is good. Definitely on favorite song li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1frIzjJv5E</td>\n",
       "      <td>['I think I would sound better at the original...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPqaRRdb7eQ</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                           comments\n",
       "0  2raUmsKIG6U  ['That is some cool grafiti song, sick!', 'Dam...\n",
       "1  3XAkH0w3QLc  ['the \"jake young\" at the begining scared me l...\n",
       "2  hXe0Elz7WV8  ['This is good. Definitely on favorite song li...\n",
       "3  x1frIzjJv5E  ['I think I would sound better at the original...\n",
       "4  iPqaRRdb7eQ                                                 []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.read_csv('new_comments.csv', encoding=\"utf-8\")  # note no moods column\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_videos_df = pd.merge(videos_df, comments_df, on='video_id')\n",
    "# use above line as example, if need to merge new_comments and new_videos csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and tokenizing the comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'That is some cool grafiti song, sick!\\', \\'Damn this is dope, I miss the 90s\\', \\'Nice beat and cuts man, unfortunately they faded so early.\\', \\'Very nice beat bra\\', \\'Can you feel IT can you feel IT can you feeeeel itttt\\', \\'this is super golden age hip hop, but still so atmospheric with that string sample!! i just dropped a new vid on my channel would love to hear the opinion of a true artist like you over there! love this beat tho bro!\\', \\'Gj /GoodJob!\\', \\'Se puede sacar una super improvisacion buen beat\\', \"Hello. I want to use ur music for a dance project but i can\\'t find you on facebook, and also not on soundcloud. How can i get your music? Thank you\", \"who\\'s down to start a rap group\", \\'You bouta get the cred for some slick shit bro this beat is fucking absurd\\', \"It\\'s ok if not\", \\'Can I use this brother?\\', \\'Hola man queria saber si podia utilizar este  beat para un tema que tengo pensado (se llama \"mientras suenan las sirenas ) y es justo lo que me imagine para el tema queria saber si tenia tu okey y obiamente siguiendo lo q dice en la descripcion de todos modos gracias y muy buen beat\\', \\'Great\\', \\'Amazing beat🔥\\', \\'Can I use this beat\\\\nI will give you credit also\\', \\'brilliant\\', \"Bro it\\'s the best ever beat i have ever heard\", \\'nice work bro, check my new wc beat: https://goo.gl/87Ueiw\\']'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the raw comments for the first video\n",
    "first_vid_comments = comments_df.comments.values[0]\n",
    "first_vid_comments  # NOTE: this whole object is a string; change it to a list with strings inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried various operations on first video comments\n",
    "# Create a list object of first video comments by splitting on \"\\', \" -- not successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'the \"jake young\" at the begining scared me lolol\\', \\'oml there are literally 4-5 comments with lyrics i cant-\\', \\'NNA NANANA NANAN NANANNAANNNAANANANANANANANANANANANNNNANANANANANANANANAN*YUMINOSHIi?b0AI\\', \\'Chi è qui per Klaus? 🇮🇹🇮🇹🇮🇹\\', \\'great job, can I use it for a cover? :) thank you\\', \\'Shut your mouth, I don’t wanna fuckin breath now\\\\nAll the people on my back I’m getting weighed down \\\\nMy future’s falling to the floor, I’m getting worried now\\\\nWill I make it in this game or will I fuckin drown\\\\n\\\\nI can’t fuckin sleep\\\\nI can’t fuckin breath \\\\nAll these pills are on my mind, now I’m in this deep\\\\nFinally passed out on the floor from all this codeine \\\\nShe be screaming I want more until she fuck me\\\\n\\\\nLife’s a bitter mess when you are depressed \\\\nAll these demons in my head I’m feeling possessed\\\\nI got problems with these women, yeah I’m obsessed \\\\nEvery day I’m working hard creating progress \\\\n\\\\nWhen I wake up and I know you’re on my fucking mind \\\\nI can’t face it, you just take up all my fucking time\\\\nI’m taking chemicals to get me through this fuckin life \\\\nI say I’m good and she know it’s a fucking lie\\\\n\\\\nWill they ever listen to me \\\\nYou wanna lead and I wanna leave \\\\nWanna feel like you’re fuckin free\\\\nWell here you go, baby take my sleep\\\\n\\\\nWhen I wake up and I know you’re on my fucking mind \\\\nI can’t face it, you just take up all my fucking time\\\\nI’m taking chemicals to get me through this fuckin life \\\\nI say I’m good and she know it’s a fucking lie\\', \\'Hi! would also like to use your music for a cover. is that cool? Will credit you :)\\', \\'Awesome work❤ also, thank you sooo much for putting the sheets available! 😊\\', \\'CAN I USE THIS FOR A COVER? 😍🙋🏼\\\\u200d♂️\\', \\'This is so gorgeous. Thank you\\', \\'Gard bless you for this!\\', \\'can I use this for my video?\\', \\'Beautiful!\\\\nThe only thing you\\\\\\'re missing is that one part with the \"You caused it\", I can\\\\\\'t describe it. But it\\\\\\'s accompanied by a guitar you can only hear in your right ear. I hope you understand. But it\\\\\\'s beautiful regardless. I\\\\\\'d just love it even more if you include it.\\', \\'could you do Already Gone by Sleeping At Last? there are no instrumentals out for it it would be amazing :) thanks x\\', \"Would it be okay to use this for my cover? I\\'ll give credit :D\", \\'Wonderful ... and hopeful.\\', \\'Thank the lord this exists.\\', \\'may i use this for a cover ??\\', \\'I would love to do a cover of this song. I will give credit of course :3\\', \\'Hey can I choreograph a dance to this for a show at the end of this semester? I’ll credit you\\']'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the raw comments for the second video\n",
    "second_vid_comments = comments_df.comments.values[1]\n",
    "second_vid_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study all comments for all videos\n",
    "# Based on methods from aws-sagemaker-python-notebook [not yet updated on github]\n",
    "all_comments = []\n",
    "all_comments_dict = {}\n",
    "for comment_group in list(comments_df.comments):\n",
    "    comment_group = comment_group.replace('[', '')\n",
    "    comment_group = comment_group.replace(']', '')\n",
    "    comment_group = comment_group.replace(\"'\", '')\n",
    "    all_comments.append(comment_group)\n",
    "    # if ', ' in comment_group:\n",
    "    #     comment_group = comment_group.split(', ')\n",
    "    #     for item in comment_group:\n",
    "    #         all_comments.append(comment_group)\n",
    "    # print(comment_group, len(comment_group))\n",
    "\n",
    "print('length of all_comments is:', len(all_comments))\n",
    "print(all_comments[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lower-case, do several char replacements, and create list by splitting comments string\n",
    "\n",
    "# Create a function to do this when applied to all values in df's comments column\n",
    "\n",
    "def normalize_text(comment_group):\n",
    "    norm_comment_group = comment_group.lower()\n",
    "    norm_comment_group = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_comment_group)\n",
    "    norm_comment_group = norm_comment_group.replace('\\\\n', ', ')\n",
    "    norm_comment_group = norm_comment_group.replace('\"', \"\\'\")\n",
    "    while \"\\'\" in norm_comment_group:\n",
    "        norm_comment_group = norm_comment_group.replace(\"\\'\", '')\n",
    "    norm_comment_group = norm_comment_group.replace('[', '')\n",
    "    norm_comment_group = norm_comment_group.replace(']', '')\n",
    "    return norm_comment_group\n",
    "\n",
    "# Apply normalize_text function to all comments column values\n",
    "\n",
    "comments_df.comments = comments_df.comments.apply(lambda x: normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['that is some cool grafiti song ,  sick !  ,  damn this is dope ,  i miss the 90s ,  nice beat and cuts man ,  unfortunately they faded so early .  ,  very nice beat bra ,  can you feel it can you feel it can you feeeeel itttt ,  this is super golden age hip hop ,  but still so atmospheric with that string sample !  !  i just dropped a new vid on my channel would love to hear the opinion of a true artist like you over there !  love this beat tho bro !  ,  gj /goodjob !  ,  se puede sacar una super improvisacion buen beat ,    hello .  i want to use ur music for a dance project but i cant find you on facebook ,  and also not on soundcloud .  how can i get your music ?  thank you   ,    whos down to start a rap group   ,  you bouta get the cred for some slick shit bro this beat is fucking absurd ,    its ok if not   ,  can i use this brother ?  ,  hola man queria saber si podia utilizar este  beat para un tema que tengo pensado  ( se llama   mientras suenan las sirenas  )  y es justo lo que me imagine para el tema queria saber si tenia tu okey y obiamente siguiendo lo q dice en la descripcion de todos modos gracias y muy buen beat ,  great ,  amazing beat🔥 ,  can i use this beat, i will give you credit also ,  brilliant ,    bro its the best ever beat i have ever heard   ,  nice work bro ,  check my new wc beat :  https : //goo . gl/87ueiw',\n",
       "       'the   jake young   at the begining scared me lolol ,  oml there are literally 4-5 comments with lyrics i cant- ,  nna nanana nanan nanannaannnaananananananananananannnnananananananananan*yuminoshii ? b0ai ,  chi è qui per klaus ?  🇮🇹🇮🇹🇮🇹 ,  great job ,  can i use it for a cover ?   :  )  thank you ,  shut your mouth ,  i don’t wanna fuckin breath now, all the people on my back i’m getting weighed down , my future’s falling to the floor ,  i’m getting worried now, will i make it in this game or will i fuckin drown, , i can’t fuckin sleep, i can’t fuckin breath , all these pills are on my mind ,  now i’m in this deep, finally passed out on the floor from all this codeine , she be screaming i want more until she fuck me, , life’s a bitter mess when you are depressed , all these demons in my head i’m feeling possessed, i got problems with these women ,  yeah i’m obsessed , every day i’m working hard creating progress , , when i wake up and i know you’re on my fucking mind , i can’t face it ,  you just take up all my fucking time, i’m taking chemicals to get me through this fuckin life , i say i’m good and she know it’s a fucking lie, , will they ever listen to me , you wanna lead and i wanna leave , wanna feel like you’re fuckin free, well here you go ,  baby take my sleep, , when i wake up and i know you’re on my fucking mind , i can’t face it ,  you just take up all my fucking time, i’m taking chemicals to get me through this fuckin life , i say i’m good and she know it’s a fucking lie ,  hi !  would also like to use your music for a cover .  is that cool ?  will credit you  :  )  ,  awesome work❤ also ,  thank you sooo much for putting the sheets available !  😊 ,  can i use this for a cover ?  😍🙋🏼\\\\u200d♂️ ,  this is so gorgeous .  thank you ,  gard bless you for this !  ,  can i use this for my video ?  ,  beautiful ! , the only thing you\\\\re missing is that one part with the   you caused it   ,  i can\\\\t describe it .  but it\\\\s accompanied by a guitar you can only hear in your right ear .  i hope you understand .  but it\\\\s beautiful regardless .  i\\\\d just love it even more if you include it .  ,  could you do already gone by sleeping at last ?  there are no instrumentals out for it it would be amazing  :  )  thanks x ,    would it be okay to use this for my cover ?  ill give credit  : d   ,  wonderful  .  .  .  and hopeful .  ,  thank the lord this exists .  ,  may i use this for a cover  ?  ?  ,  i would love to do a cover of this song .  i will give credit of course  : 3 ,  hey can i choreograph a dance to this for a show at the end of this semester ?  i’ll credit you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.comments.values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fourth video, with id iPqaRRdb7eQ, has no comments. \n",
    "comments_df.comments.values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(sent_1)  # Example of using NLTK to tokenize one video's comments as one sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying TextBlob for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with the first video's comments, to start\n",
    "\n",
    "blob = TextBlob(comments_df.comments.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('some', 'DT'),\n",
       " ('cool', 'JJ'),\n",
       " ('grafiti', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('sick', 'NN'),\n",
       " ('damn', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('dope', 'NN'),\n",
       " ('i', 'JJ'),\n",
       " ('miss', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('90s', 'CD'),\n",
       " ('nice', 'JJ'),\n",
       " ('beat', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('cuts', 'NNS'),\n",
       " ('man', 'NN'),\n",
       " ('unfortunately', 'RB'),\n",
       " ('they', 'PRP'),\n",
       " ('faded', 'VBD'),\n",
       " ('so', 'RB'),\n",
       " ('early', 'JJ'),\n",
       " ('very', 'RB'),\n",
       " ('nice', 'JJ'),\n",
       " ('beat', 'NN'),\n",
       " ('bra', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('feel', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('feel', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('feeeeel', 'VB'),\n",
       " ('itttt', 'RB'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('super', 'JJ'),\n",
       " ('golden', 'JJ'),\n",
       " ('age', 'NN'),\n",
       " ('hip', 'NN'),\n",
       " ('hop', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('still', 'RB'),\n",
       " ('so', 'RB'),\n",
       " ('atmospheric', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('string', 'VBG'),\n",
       " ('sample', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('just', 'RB'),\n",
       " ('dropped', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('vid', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('channel', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('love', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('hear', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('opinion', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('true', 'JJ'),\n",
       " ('artist', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('over', 'IN'),\n",
       " ('there', 'RB'),\n",
       " ('love', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('beat', 'NN'),\n",
       " ('tho', 'JJ'),\n",
       " ('bro', 'NN'),\n",
       " ('gj', 'JJ'),\n",
       " ('/goodjob', 'NN'),\n",
       " ('se', 'FW'),\n",
       " ('puede', 'NN'),\n",
       " ('sacar', 'NN'),\n",
       " ('una', 'JJ'),\n",
       " ('super', 'JJ'),\n",
       " ('improvisacion', 'NN'),\n",
       " ('buen', 'NN'),\n",
       " ('beat', 'NN'),\n",
       " ('hello', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('use', 'VB'),\n",
       " ('ur', 'JJ'),\n",
       " ('music', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('dance', 'NN'),\n",
       " ('project', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('i', 'JJ'),\n",
       " ('cant', 'VBP'),\n",
       " ('find', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('on', 'IN'),\n",
       " ('facebook', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('also', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('soundcloud', 'NN'),\n",
       " ('how', 'WRB'),\n",
       " ('can', 'MD'),\n",
       " ('i', 'VB'),\n",
       " ('get', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('music', 'NN'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('whos', 'VB'),\n",
       " ('down', 'RP'),\n",
       " ('to', 'TO'),\n",
       " ('start', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('rap', 'NN'),\n",
       " ('group', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('bouta', 'VBP'),\n",
       " ('get', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('cred', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('slick', 'JJ'),\n",
       " ('shit', 'NN'),\n",
       " ('bro', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('beat', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('fucking', 'VBG'),\n",
       " ('absurd', 'RB'),\n",
       " ('its', 'PRP$'),\n",
       " ('ok', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('can', 'MD'),\n",
       " ('i', 'VB'),\n",
       " ('use', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('brother', 'NN'),\n",
       " ('hola', 'NN'),\n",
       " ('man', 'NN'),\n",
       " ('queria', 'VBZ'),\n",
       " ('saber', 'JJ'),\n",
       " ('si', 'JJ'),\n",
       " ('podia', 'NN'),\n",
       " ('utilizar', 'JJ'),\n",
       " ('este', 'NN'),\n",
       " ('beat', 'NN'),\n",
       " ('para', 'NN'),\n",
       " ('un', 'JJ'),\n",
       " ('tema', 'NN'),\n",
       " ('que', 'NN'),\n",
       " ('tengo', 'NN'),\n",
       " ('pensado', 'NN'),\n",
       " ('se', 'JJ'),\n",
       " ('llama', 'NN'),\n",
       " ('mientras', 'NNS'),\n",
       " ('suenan', 'VBP'),\n",
       " ('las', 'NNS'),\n",
       " ('sirenas', 'NNS'),\n",
       " ('y', 'VBP'),\n",
       " ('es', 'JJ'),\n",
       " ('justo', 'NN'),\n",
       " ('lo', 'NN'),\n",
       " ('que', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('imagine', 'VBP'),\n",
       " ('para', 'JJ'),\n",
       " ('el', 'NN'),\n",
       " ('tema', 'NN'),\n",
       " ('queria', 'NNS'),\n",
       " ('saber', 'VBP'),\n",
       " ('si', 'JJ'),\n",
       " ('tenia', 'NN'),\n",
       " ('tu', 'NN'),\n",
       " ('okey', 'JJ'),\n",
       " ('y', 'NN'),\n",
       " ('obiamente', 'NN'),\n",
       " ('siguiendo', 'NN'),\n",
       " ('lo', 'NN'),\n",
       " ('q', 'NN'),\n",
       " ('dice', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('la', 'FW'),\n",
       " ('descripcion', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('todos', 'FW'),\n",
       " ('modos', 'FW'),\n",
       " ('gracias', 'FW'),\n",
       " ('y', 'FW'),\n",
       " ('muy', 'FW'),\n",
       " ('buen', 'NN'),\n",
       " ('beat', 'NN'),\n",
       " ('great', 'JJ'),\n",
       " ('amazing', 'JJ'),\n",
       " ('beat🔥', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('i', 'VB'),\n",
       " ('use', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('beat', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('give', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('credit', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('brilliant', 'JJ'),\n",
       " ('bro', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('ever', 'RB'),\n",
       " ('beat', 'VBP'),\n",
       " ('i', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('ever', 'RB'),\n",
       " ('heard', 'VBN'),\n",
       " ('nice', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('bro', 'NN'),\n",
       " ('check', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('new', 'JJ'),\n",
       " ('wc', 'JJ'),\n",
       " ('beat', 'NN'),\n",
       " ('https', 'NN'),\n",
       " ('//goo', 'NN'),\n",
       " ('gl/87ueiw', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if we can get tags for the first video's comments\n",
    "\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity and subjectivity for this sentence are: Sentiment(polarity=-0.27142857142857146, subjectivity=0.7535714285714286)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.06666666666666667, subjectivity=0.7666666666666666)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.35333333333333333, subjectivity=0.5416666666666666)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.3579545454545454, subjectivity=0.5681818181818182)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.625, subjectivity=0.6)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.3333333333333333, subjectivity=0.6666666666666666)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=-0.12111111111111113, subjectivity=0.5927777777777778)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.6727272727272728, subjectivity=0.734090909090909)\n",
      "polarity and subjectivity for this sentence are: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "polarity_list is: [-0.27142857142857146, 0.06666666666666667, 0.35333333333333333, 0.3579545454545454, 0.625, 0.3333333333333333, -0.12111111111111113, 0.6727272727272728] \n",
      " subjectivity_list is: [0.7535714285714286, 0.7666666666666666, 0.5416666666666666, 0.5681818181818182, 0.6, 0.6666666666666666, 0.5927777777777778, 0.734090909090909]\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "polarity_list = []\n",
    "subjectivity_list = []\n",
    "for sentence in blob.sentences:\n",
    "    print('polarity and subjectivity for this sentence are:', sentence.sentiment)\n",
    "    polarity = sentence.sentiment.polarity\n",
    "    subjectivity = sentence.sentiment.subjectivity\n",
    "    if polarity !=0 :\n",
    "        polarity_list.append(polarity)\n",
    "    if subjectivity !=0 :\n",
    "        subjectivity_list.append(subjectivity)\n",
    "print('polarity_list is:', polarity_list, '\\n', 'subjectivity_list is:', subjectivity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two new columns to comments_df: one each for TextBlob polarity mean and subjectivity mean\n",
    "\n",
    "tblob_vids_comments_df = pd.concat(\n",
    "    [comments_df, pd.DataFrame(columns=['polarity_mean', 'subjectivity_mean', 'tags'])], axis=1)\n",
    "\n",
    "# full_videos_df = pd.merge(videos_df, comments_df, on='video_id')\n",
    "tblob_vids_comments_df = pd.merge(tblob_vids_comments_df, videos_df, on='video_id')\n",
    "cols = tblob_vids_comments_df.columns.to_list()\n",
    "cols = [cols[0]] + [cols[5]] + [cols[1]] + cols[2:5] + [cols[-1]]\n",
    "tblob_vids_comments_df = tblob_vids_comments_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comments</th>\n",
       "      <th>polarity_mean</th>\n",
       "      <th>subjectivity_mean</th>\n",
       "      <th>tags</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2raUmsKIG6U</td>\n",
       "      <td>[SOLD]\" Graffiti \" - 90s Old School Storytelli...</td>\n",
       "      <td>that is some cool grafiti song ,  sick !  ,  d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3XAkH0w3QLc</td>\n",
       "      <td>Youth by Daughter | Instrumental (w/ Sheet Music)</td>\n",
       "      <td>the   jake young   at the begining scared me l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hXe0Elz7WV8</td>\n",
       "      <td>THE CREATOR LIED TO US (Fansong Instrumental) ...</td>\n",
       "      <td>this is good .  definitely on favorite song li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1frIzjJv5E</td>\n",
       "      <td>Kendrick Lamar - Blood. (RoadsArt Instrumental...</td>\n",
       "      <td>i think i would sound better at the original s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPqaRRdb7eQ</td>\n",
       "      <td>Nco Qub Hluas Nraug Instrumental + Lyrics - Gi...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  2raUmsKIG6U  [SOLD]\" Graffiti \" - 90s Old School Storytelli...   \n",
       "1  3XAkH0w3QLc  Youth by Daughter | Instrumental (w/ Sheet Music)   \n",
       "2  hXe0Elz7WV8  THE CREATOR LIED TO US (Fansong Instrumental) ...   \n",
       "3  x1frIzjJv5E  Kendrick Lamar - Blood. (RoadsArt Instrumental...   \n",
       "4  iPqaRRdb7eQ  Nco Qub Hluas Nraug Instrumental + Lyrics - Gi...   \n",
       "\n",
       "                                            comments polarity_mean  \\\n",
       "0  that is some cool grafiti song ,  sick !  ,  d...           NaN   \n",
       "1  the   jake young   at the begining scared me l...           NaN   \n",
       "2  this is good .  definitely on favorite song li...           NaN   \n",
       "3  i think i would sound better at the original s...           NaN   \n",
       "4                                                              NaN   \n",
       "\n",
       "  subjectivity_mean tags            moods  \n",
       "0               NaN  NaN            CHILL  \n",
       "1               NaN  NaN            CHILL  \n",
       "2               NaN  NaN  CONFIDENT-SASSY  \n",
       "3               NaN  NaN            CHILL  \n",
       "4               NaN  NaN            CHILL  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tblob_vids_comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TextBlob mean polarity, mean subjectivity, and tags for all comments for each video\n",
    "# Write functions to do each of the following:\n",
    "# 1) run TextBlob on comments; 2) populate polarity_mean, subjectivity_mean, and tags values\n",
    "\n",
    "def get_blob(comments):\n",
    "    \"\"\"Use with one video's comments at a time.\"\"\"\n",
    "    blob = TextBlob(comments)\n",
    "    polarity_list = []\n",
    "    subjectivity_list = []\n",
    "    for sentence in blob.sentences:\n",
    "        polarity = sentence.sentiment.polarity\n",
    "        subjectivity = sentence.sentiment.subjectivity\n",
    "        if polarity !=0 :\n",
    "            polarity_list.append(polarity)\n",
    "        if subjectivity !=0 :\n",
    "            subjectivity_list.append(subjectivity)\n",
    "    if len(polarity_list) == 0:\n",
    "        polarity_list = [0]\n",
    "    if len(subjectivity_list) == 0:\n",
    "        subjectivity_list = [0]\n",
    "    return mean(polarity_list), mean(subjectivity_list), blob.tags\n",
    "\n",
    "\n",
    "def populate_blob_columns(comms):\n",
    "    \"\"\"Use to fill the polarity_mean, subjectivity_mean, and tags columns.\"\"\"\n",
    "    polarity_mean, subjectivity_mean, tags = get_blob(comms)\n",
    "    tblob_vids_comments_df.loc[(tblob_vids_comments_df.comments == comms), 'polarity_mean'] = polarity_mean\n",
    "    tblob_vids_comments_df.loc[(tblob_vids_comments_df.comments == comms), 'subjectivity_mean'] = subjectivity_mean\n",
    "    tblob_vids_comments_df.loc[(tblob_vids_comments_df.comments == comms), 'tags'] = [tags]\n",
    "\n",
    "\n",
    "for comments in tblob_vids_comments_df.comments.values:\n",
    "    populate_blob_columns(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comments</th>\n",
       "      <th>polarity_mean</th>\n",
       "      <th>subjectivity_mean</th>\n",
       "      <th>tags</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fWOMRvGMO3s</td>\n",
       "      <td>DAGames - Left Behind  [Instrumental] [Remake ...</td>\n",
       "      <td>no offense but this isn’t accurate .  ,  nice ...</td>\n",
       "      <td>0.66125</td>\n",
       "      <td>0.800833</td>\n",
       "      <td>[(no, DT), (offense, NN), (but, CC), (this, DT...</td>\n",
       "      <td>ANGRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NNexDl8QF6U</td>\n",
       "      <td>Chidinma - Gone forever | Karaoke Version ( In...</td>\n",
       "      <td>please do a karaoke of    let go   locko ,  th...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>[(please, VB), (do, VB), (a, DT), (karaoke, NN...</td>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>eRt8RY71hiY</td>\n",
       "      <td>Teppen E Dash Full  Instrumental</td>\n",
       "      <td>rising !  !  😍 ,  fire lemonade rising ,  inaz...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.26</td>\n",
       "      <td>[(rising, VBG), (😍, NN), (fire, NN), (lemonade...</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>FWOjSjqBUuk</td>\n",
       "      <td>Deuce - Nightmare Instrumental (Studio Quality)</td>\n",
       "      <td>it would be kickass if someone can take an aca...</td>\n",
       "      <td>0.434331</td>\n",
       "      <td>0.729861</td>\n",
       "      <td>[(it, PRP), (would, MD), (be, VB), (kickass, V...</td>\n",
       "      <td>ANGRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>pFPUeoU418k</td>\n",
       "      <td>\"Dios esta aqui\" Musica Instrumental para orar...</td>\n",
       "      <td>queridos amigos ,  quiero invitarlos a escucha...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.425</td>\n",
       "      <td>[(queridos, NN), (amigos, NNS), (quiero, NN), ...</td>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bUMFOIAbH4s</td>\n",
       "      <td>♫ Instrumental : Yandere Chan VS Monika - [ EP...</td>\n",
       "      <td>2 : 40 la partie tros bien ,  monika extended ...</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>[(2, CD), (40, CD), (la, NN), (partie, NN), (t...</td>\n",
       "      <td>ANGRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>WgYXtbtCTzY</td>\n",
       "      <td>Hluas Nraug Vib Nais Instrumental + Lyrics - L...</td>\n",
       "      <td>ua tsaug rau koj cov instrumental os</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(ua, JJ), (tsaug, NN), (rau, NN), (koj, NN), ...</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>_ntkv1ovpW8</td>\n",
       "      <td>Ib Sim Neej Instrumental + Lyrics - Hmong sad ...</td>\n",
       "      <td>ua neeg byob hauv ntiaj teb nos khos siab heev os</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(ua, JJ), (neeg, JJ), (byob, NN), (hauv, NN),...</td>\n",
       "      <td>IN-LOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>eVTfwFk70wc</td>\n",
       "      <td>Dilated Peoples  - Basics (Instrumental)</td>\n",
       "      <td>one day ill still find this sample .</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[(one, CD), (day, NN), (ill, VB), (still, RB),...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>14Cgt0oQ8aY</td>\n",
       "      <td>[FREE] Sad Drake x Logic Type Beat \"Haiku\" | C...</td>\n",
       "      <td>drop a comment and i’ll sub to your channel , ...</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>[(drop, NN), (a, DT), (comment, NN), (and, CC)...</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9CrslZs_1xA</td>\n",
       "      <td>Kabza De small_Umshove (Instrumental) &amp; Black ...</td>\n",
       "      <td>muur that joy joy is lit ,  give us some tutor...</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.62</td>\n",
       "      <td>[(muur, NN), (that, WDT), (joy, NN), (joy, NN)...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>kmLvR68_nLg</td>\n",
       "      <td>8 Remix - Almighty ft. Varios [INSTRUMENTAL + ...</td>\n",
       "      <td>￼￼￼, , ￼, , ocho, , almighty, , letra, , ￼￼￼￼,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(￼￼￼, NN), (￼, NNP), (ocho, UH), (almighty, R...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1QejWtVKE8s</td>\n",
       "      <td>【Off Vocal】Yasuha. - I Lost Your Love feat. Ha...</td>\n",
       "      <td>l o v e i t ,  歌いたくなっても神曲を汚しそうになる .  .  .  (  ...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>[(l, NN), (o, MD), (v, VB), (e, NN), (i, NN), ...</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1wopHaiFqUI</td>\n",
       "      <td>Old School Love Instrumental Produce by TBD. [...</td>\n",
       "      <td>คิดถึงพี่นะ ,  ทำเพลงต่อเถอะคับอยากฟัง😔 ,  หาย...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[(คิดถึงพี่นะ, NN), (ทำเพลงต่อเถอะคับอยากฟัง😔,...</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>YE11lAgCaAU</td>\n",
       "      <td>[Deemo 2.0] Fluquor [Instrumental] [Full HD]</td>\n",
       "      <td>https : //youtu . be/bxy2krslv9c hey guys firs...</td>\n",
       "      <td>0.172718</td>\n",
       "      <td>0.540079</td>\n",
       "      <td>[(https, NN), (//youtu, NN), (be/bxy2krslv9c, ...</td>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>E5SWz3suC2o</td>\n",
       "      <td>Famous Dex, Lil Pump, Smokepurpp - Two Guns ((...</td>\n",
       "      <td>its yung charc ,  this beat is pure comethazin...</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.474698</td>\n",
       "      <td>[(its, PRP$), (yung, NN), (charc, NN), (this, ...</td>\n",
       "      <td>CHILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Vt6adjjww9g</td>\n",
       "      <td>Akapellah - Milki (Remake - Instrumental)</td>\n",
       "      <td>https : //www . youtube . com/watch ? v=rak5d-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(https, NN), (//www, NN), (youtube, NN), (com...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>E6dqEdx3Org</td>\n",
       "      <td>Migos - I Can ((INSTRUMENTAL))</td>\n",
       "      <td>oh my god dude thank you bro thank god bro ,  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(oh, UH), (my, PRP$), (god, JJ), (dude, NN), ...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-SzIFcsrFTk</td>\n",
       "      <td>\"Reset\" - An Okami Arrangement (Instrumental)</td>\n",
       "      <td>this, is, a, beautiful, heavenly , epic, m a s...</td>\n",
       "      <td>0.372667</td>\n",
       "      <td>0.729611</td>\n",
       "      <td>[(this, DT), (is, VBZ), (a, DT), (beautiful, N...</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ZgO2pN2xmVU</td>\n",
       "      <td>Logic - Indica Badu ft. Wiz Khalifa [Instrumen...</td>\n",
       "      <td>how wiz not gonna give bobby the laugh !  ? , ...</td>\n",
       "      <td>0.264432</td>\n",
       "      <td>0.47553</td>\n",
       "      <td>[(how, WRB), (wiz, JJ), (not, RB), (gon, VBG),...</td>\n",
       "      <td>CONFIDENT-SASSY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id                                        video_title  \\\n",
       "72  fWOMRvGMO3s  DAGames - Left Behind  [Instrumental] [Remake ...   \n",
       "73  NNexDl8QF6U  Chidinma - Gone forever | Karaoke Version ( In...   \n",
       "74  eRt8RY71hiY                   Teppen E Dash Full  Instrumental   \n",
       "75  FWOjSjqBUuk    Deuce - Nightmare Instrumental (Studio Quality)   \n",
       "76  pFPUeoU418k  \"Dios esta aqui\" Musica Instrumental para orar...   \n",
       "77  bUMFOIAbH4s  ♫ Instrumental : Yandere Chan VS Monika - [ EP...   \n",
       "78  WgYXtbtCTzY  Hluas Nraug Vib Nais Instrumental + Lyrics - L...   \n",
       "79  _ntkv1ovpW8  Ib Sim Neej Instrumental + Lyrics - Hmong sad ...   \n",
       "80  eVTfwFk70wc           Dilated Peoples  - Basics (Instrumental)   \n",
       "81  14Cgt0oQ8aY  [FREE] Sad Drake x Logic Type Beat \"Haiku\" | C...   \n",
       "82  9CrslZs_1xA  Kabza De small_Umshove (Instrumental) & Black ...   \n",
       "83  kmLvR68_nLg  8 Remix - Almighty ft. Varios [INSTRUMENTAL + ...   \n",
       "84  1QejWtVKE8s  【Off Vocal】Yasuha. - I Lost Your Love feat. Ha...   \n",
       "85  1wopHaiFqUI  Old School Love Instrumental Produce by TBD. [...   \n",
       "86  YE11lAgCaAU       [Deemo 2.0] Fluquor [Instrumental] [Full HD]   \n",
       "87  E5SWz3suC2o  Famous Dex, Lil Pump, Smokepurpp - Two Guns ((...   \n",
       "88  Vt6adjjww9g          Akapellah - Milki (Remake - Instrumental)   \n",
       "89  E6dqEdx3Org                     Migos - I Can ((INSTRUMENTAL))   \n",
       "90  -SzIFcsrFTk      \"Reset\" - An Okami Arrangement (Instrumental)   \n",
       "91  ZgO2pN2xmVU  Logic - Indica Badu ft. Wiz Khalifa [Instrumen...   \n",
       "\n",
       "                                             comments polarity_mean  \\\n",
       "72  no offense but this isn’t accurate .  ,  nice ...       0.66125   \n",
       "73  please do a karaoke of    let go   locko ,  th...          0.45   \n",
       "74  rising !  !  😍 ,  fire lemonade rising ,  inaz...         0.325   \n",
       "75  it would be kickass if someone can take an aca...      0.434331   \n",
       "76  queridos amigos ,  quiero invitarlos a escucha...         0.125   \n",
       "77  2 : 40 la partie tros bien ,  monika extended ...        0.4125   \n",
       "78               ua tsaug rau koj cov instrumental os             0   \n",
       "79  ua neeg byob hauv ntiaj teb nos khos siab heev os             0   \n",
       "80            one day ill still find this sample .             -0.5   \n",
       "81  drop a comment and i’ll sub to your channel , ...      0.765278   \n",
       "82  muur that joy joy is lit ,  give us some tutor...         0.555   \n",
       "83  ￼￼￼, , ￼, , ocho, , almighty, , letra, , ￼￼￼￼,...             0   \n",
       "84  l o v e i t ,  歌いたくなっても神曲を汚しそうになる .  .  .  (  ...        0.4375   \n",
       "85  คิดถึงพี่นะ ,  ทำเพลงต่อเถอะคับอยากฟัง😔 ,  หาย...           0.2   \n",
       "86  https : //youtu . be/bxy2krslv9c hey guys firs...      0.172718   \n",
       "87  its yung charc ,  this beat is pure comethazin...        0.2636   \n",
       "88  https : //www . youtube . com/watch ? v=rak5d-...             0   \n",
       "89  oh my god dude thank you bro thank god bro ,  ...             0   \n",
       "90  this, is, a, beautiful, heavenly , epic, m a s...      0.372667   \n",
       "91  how wiz not gonna give bobby the laugh !  ? , ...      0.264432   \n",
       "\n",
       "   subjectivity_mean                                               tags  \\\n",
       "72          0.800833  [(no, DT), (offense, NN), (but, CC), (this, DT...   \n",
       "73          0.658333  [(please, VB), (do, VB), (a, DT), (karaoke, NN...   \n",
       "74              0.26  [(rising, VBG), (😍, NN), (fire, NN), (lemonade...   \n",
       "75          0.729861  [(it, PRP), (would, MD), (be, VB), (kickass, V...   \n",
       "76             0.425  [(queridos, NN), (amigos, NNS), (quiero, NN), ...   \n",
       "77            0.7425  [(2, CD), (40, CD), (la, NN), (partie, NN), (t...   \n",
       "78                 0  [(ua, JJ), (tsaug, NN), (rau, NN), (koj, NN), ...   \n",
       "79                 0  [(ua, JJ), (neeg, JJ), (byob, NN), (hauv, NN),...   \n",
       "80                 1  [(one, CD), (day, NN), (ill, VB), (still, RB),...   \n",
       "81          0.683333  [(drop, NN), (a, DT), (comment, NN), (and, CC)...   \n",
       "82              0.62  [(muur, NN), (that, WDT), (joy, NN), (joy, NN)...   \n",
       "83                 0  [(￼￼￼, NN), (￼, NNP), (ocho, UH), (almighty, R...   \n",
       "84            0.6725  [(l, NN), (o, MD), (v, VB), (e, NN), (i, NN), ...   \n",
       "85              0.15  [(คิดถึงพี่นะ, NN), (ทำเพลงต่อเถอะคับอยากฟัง😔,...   \n",
       "86          0.540079  [(https, NN), (//youtu, NN), (be/bxy2krslv9c, ...   \n",
       "87          0.474698  [(its, PRP$), (yung, NN), (charc, NN), (this, ...   \n",
       "88                 0  [(https, NN), (//www, NN), (youtube, NN), (com...   \n",
       "89                 0  [(oh, UH), (my, PRP$), (god, JJ), (dude, NN), ...   \n",
       "90          0.729611  [(this, DT), (is, VBZ), (a, DT), (beautiful, N...   \n",
       "91           0.47553  [(how, WRB), (wiz, JJ), (not, RB), (gon, VBG),...   \n",
       "\n",
       "              moods  \n",
       "72            ANGRY  \n",
       "73              SAD  \n",
       "74            CHILL  \n",
       "75            ANGRY  \n",
       "76              SAD  \n",
       "77            ANGRY  \n",
       "78            CHILL  \n",
       "79          IN-LOVE  \n",
       "80  CONFIDENT-SASSY  \n",
       "81            CHILL  \n",
       "82  CONFIDENT-SASSY  \n",
       "83  CONFIDENT-SASSY  \n",
       "84            CHILL  \n",
       "85            HAPPY  \n",
       "86              SAD  \n",
       "87            CHILL  \n",
       "88  CONFIDENT-SASSY  \n",
       "89  CONFIDENT-SASSY  \n",
       "90            HAPPY  \n",
       "91  CONFIDENT-SASSY  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how df looks, prior to sending to csv\n",
    "print(tblob_vids_comments_df.shape)\n",
    "tblob_vids_comments_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv for sharing data outside of notebook\n",
    "\n",
    "tblob_vids_comments_df.to_csv('videos_with_nlp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Doc2Vec NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a Doc2Vec TaggedDocument for each video's comments;\n",
    "# append each of those Doc2Vec TaggedDocuments to a \"sentences\" list;\n",
    "# create: model = models.Doc2Vec(alpha=.025, min_alpha=.025, min_count=1);\n",
    "# call: model.build_vocab(sentences);\n",
    "# train model: for epoch in range(int):... model.train, model.alpha, model.min_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument count in sentences is: 93 \n",
      "\n",
      "TaggedDocument(that is some cool grafiti song ,  sick !  ,  damn this is dope ,  i miss the 90s ,  nice beat and cuts man ,  unfortunately they faded so early .  ,  very nice beat bra ,  can you feel it can you feel it can you feeeeel itttt ,  this is super golden age hip hop ,  but still so atmospheric with that string sample !  !  i just dropped a new vid on my channel would love to hear the opinion of a true artist like you over there !  love this beat tho bro !  ,  gj /goodjob !  ,  se puede sacar una super improvisacion buen beat ,    hello .  i want to use ur music for a dance project but i cant find you on facebook ,  and also not on soundcloud .  how can i get your music ?  thank you   ,    whos down to start a rap group   ,  you bouta get the cred for some slick shit bro this beat is fucking absurd ,    its ok if not   ,  can i use this brother ?  ,  hola man queria saber si podia utilizar este  beat para un tema que tengo pensado  ( se llama   mientras suenan las sirenas  )  y es justo lo que me imagine para el tema queria saber si tenia tu okey y obiamente siguiendo lo q dice en la descripcion de todos modos gracias y muy buen beat ,  great ,  amazing beat🔥 ,  can i use this beat, i will give you credit also ,  brilliant ,    bro its the best ever beat i have ever heard   ,  nice work bro ,  check my new wc beat :  https : //goo . gl/87ueiw, ['SENT_0'])\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "sentences_ordered_dict = OrderedDict()\n",
    "sent_count = 0\n",
    "raw_comments = list(comments_df.comments.values)  # this is all of the comments for all videos\n",
    "for comment_group in raw_comments:\n",
    "    sent_key = 'sentence' + str(sent_count)\n",
    "    sentences_ordered_dict[sent_key] = doc2vec.TaggedDocument(\n",
    "        words=comment_group, tags=[\"SENT_\" + str(sent_count)])\n",
    "    sentences.append(sentences_ordered_dict[sent_key])\n",
    "    sent_count += 1\n",
    "print('TaggedDocument count in sentences is:', len(sentences), '\\n')\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc2vec model and build its vocabulary\n",
    "model = Doc2Vec(alpha=.025, min_alpha=.025, min_count=2)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more info about the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which objects related to vocabulary are available in the Doc2Vec namespace\n",
    "[x for x in dir(model) if 'vocab' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look closer at 'vocabulary'\n",
    "help(model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer new tokens on new comments documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
